dbt artifacts はどのように保存されている？

---

dbt Cloud はenvironment を作り、deferral に environment を指定するけどこれはブランチを指定してる。どう思う

---

これってもうマーケットプレイスに公開されている？

---

duckdb 対応したい。

---

Base directory for this skill: /Users/ta93abe/.claude/plugins/cache/claude-plugins-official/superpowers/4.3.0/skills/brainstorming

# Brainstorming Ideas Into Designs

## Overview

Help turn ideas into fully formed designs and specs through natural collaborative dialogue.

Start by understanding the current project context, then ask questions one at a time to refine the idea. Once you understand what you're building, present the design and get user approval.

<HARD-GATE>
Do NOT invoke any implementation skill, write any code, scaffold any project, or take any implementation action until you have presented a design and the user has approved it. This applies to EVERY project regardless of perceived simplicity.
</HARD-GATE>

## Anti-Pattern: "This Is Too Simple To Need A Design"

Every project goes through this process. A todo list, a single-function utility, a config change — all of them. "Simple" projects are where unexamined assumptions cause the most wasted work. The design can be short (a few sentences for truly simple projects), but you MUST present it and get approval.

## Checklist

You MUST create a task for each of these items and complete them in order:

1. **Explore project context** — check files, docs, recent commits
2. **Ask clarifying questions** — one at a time, understand purpose/constraints/success criteria
3. **Propose 2-3 approaches** — with trade-offs and your recommendation
4. **Present design** — in sections scaled to their complexity, get user approval after each section
5. **Write design doc** — save to `docs/plans/YYYY-MM-DD-<topic>-design.md` and commit
6. **Transition to implementation** — invoke writing-plans skill to create implementation plan

## Process Flow

```dot
digraph brainstorming {
    "Explore project context" [shape=box];
    "Ask clarifying questions" [shape=box];
    "Propose 2-3 approaches" [shape=box];
    "Present design sections" [shape=box];
    "User approves design?" [shape=diamond];
    "Write design doc" [shape=box];
    "Invoke writing-plans skill" [shape=doublecircle];

    "Explore project context" -> "Ask clarifying questions";
    "Ask clarifying questions" -> "Propose 2-3 approaches";
    "Propose 2-3 approaches" -> "Present design sections";
    "Present design sections" -> "User approves design?";
    "User approves design?" -> "Present design sections" [label="no, revise"];
    "User approves design?" -> "Write design doc" [label="yes"];
    "Write design doc" -> "Invoke writing-plans skill";
}
```

**The terminal state is invoking writing-plans.** Do NOT invoke frontend-design, mcp-builder, or any other implementation skill. The ONLY skill you invoke after brainstorming is writing-plans.

## The Process

**Understanding the idea:**
- Check out the current project state first (files, docs, recent commits)
- Ask questions one at a time to refine the idea
- Prefer multiple choice questions when possible, but open-ended is fine too
- Only one question per message - if a topic needs more exploration, break it into multiple questions
- Focus on understanding: purpose, constraints, success criteria

**Exploring approaches:**
- Propose 2-3 different approaches with trade-offs
- Present options conversationally with your recommendation and reasoning
- Lead with your recommended option and explain why

**Presenting the design:**
- Once you believe you understand what you're building, present the design
- Scale each section to its complexity: a few sentences if straightforward, up to 200-300 words if nuanced
- Ask after each section whether it looks right so far
- Cover: architecture, components, data flow, error handling, testing
- Be ready to go back and clarify if something doesn't make sense

## After the Design

**Documentation:**
- Write the validated design to `docs/plans/YYYY-MM-DD-<topic>-design.md`
- Use elements-of-style:writing-clearly-and-concisely skill if available
- Commit the design document to git

**Implementation:**
- Invoke the writing-plans skill to create a detailed implementation plan
- Do NOT invoke any other skill. writing-plans is the next step.

## Key Principles

- **One question at a time** - Don't overwhelm with multiple questions
- **Multiple choice preferred** - Easier to answer than open-ended when possible
- **YAGNI ruthlessly** - Remove unnecessary features from all designs
- **Explore alternatives** - Always propose 2-3 approaches before settling
- **Incremental validation** - Present design, get approval before moving on
- **Be flexible** - Go back and clarify when something doesn't make sense

---

[Request interrupted by user]

---

実際に使ってみたんだけど、
Can't find 'action.yml', 'action.yaml' or 'Dockerfile' under '/home/runner/work/data-engineering-with-cloudflare/data-engineering-with-cloudflare/actions/setup'. Did you forget to run actions/checkout before running your local action?
こんなエラーが出る。

---

Base directory for this skill: /Users/ta93abe/.claude/plugins/cache/claude-plugins-official/superpowers/4.3.0/skills/systematic-debugging

# Systematic Debugging

## Overview

Random fixes waste time and create new bugs. Quick patches mask underlying issues.

**Core principle:** ALWAYS find root cause before attempting fixes. Symptom fixes are failure.

**Violating the letter of this process is violating the spirit of debugging.**

## The Iron Law

```
NO FIXES WITHOUT ROOT CAUSE INVESTIGATION FIRST
```

If you haven't completed Phase 1, you cannot propose fixes.

## When to Use

Use for ANY technical issue:
- Test failures
- Bugs in production
- Unexpected behavior
- Performance problems
- Build failures
- Integration issues

**Use this ESPECIALLY when:**
- Under time pressure (emergencies make guessing tempting)
- "Just one quick fix" seems obvious
- You've already tried multiple fixes
- Previous fix didn't work
- You don't fully understand the issue

**Don't skip when:**
- Issue seems simple (simple bugs have root causes too)
- You're in a hurry (rushing guarantees rework)
- Manager wants it fixed NOW (systematic is faster than thrashing)

## The Four Phases

You MUST complete each phase before proceeding to the next.

### Phase 1: Root Cause Investigation

**BEFORE attempting ANY fix:**

1. **Read Error Messages Carefully**
   - Don't skip past errors or warnings
   - They often contain the exact solution
   - Read stack traces completely
   - Note line numbers, file paths, error codes

2. **Reproduce Consistently**
   - Can you trigger it reliably?
   - What are the exact steps?
   - Does it happen every time?
   - If not reproducible → gather more data, don't guess

3. **Check Recent Changes**
   - What changed that could cause this?
   - Git diff, recent commits
   - New dependencies, config changes
   - Environmental differences

4. **Gather Evidence in Multi-Component Systems**

   **WHEN system has multiple components (CI → build → signing, API → service → database):**

   **BEFORE proposing fixes, add diagnostic instrumentation:**
   ```
   For EACH component boundary:
     - Log what data enters component
     - Log what data exits component
     - Verify environment/config propagation
     - Check state at each layer

   Run once to gather evidence showing WHERE it breaks
   THEN analyze evidence to identify failing component
   THEN investigate that specific component
   ```

   **Example (multi-layer system):**
   ```bash
   # Layer 1: Workflow
   echo "=== Secrets available in workflow: ==="
   echo "IDENTITY: ${IDENTITY:+SET}${IDENTITY:-UNSET}"

   # Layer 2: Build script
   echo "=== Env vars in build script: ==="
   env | grep IDENTITY || echo "IDENTITY not in environment"

   # Layer 3: Signing script
   echo "=== Keychain state: ==="
   security list-keychains
   security find-identity -v

   # Layer 4: Actual signing
   codesign --sign "$IDENTITY" --verbose=4 "$APP"
   ```

   **This reveals:** Which layer fails (secrets → workflow ✓, workflow → build ✗)

5. **Trace Data Flow**

   **WHEN error is deep in call stack:**

   See `root-cause-tracing.md` in this directory for the complete backward tracing technique.

   **Quick version:**
   - Where does bad value originate?
   - What called this with bad value?
   - Keep tracing up until you find the source
   - Fix at source, not at symptom

### Phase 2: Pattern Analysis

**Find the pattern before fixing:**

1. **Find Working Examples**
   - Locate similar working code in same codebase
   - What works that's similar to what's broken?

2. **Compare Against References**
   - If implementing pattern, read reference implementation COMPLETELY
   - Don't skim - read every line
   - Understand the pattern fully before applying

3. **Identify Differences**
   - What's different between working and broken?
   - List every difference, however small
   - Don't assume "that can't matter"

4. **Understand Dependencies**
   - What other components does this need?
   - What settings, config, environment?
   - What assumptions does it make?

### Phase 3: Hypothesis and Testing

**Scientific method:**

1. **Form Single Hypothesis**
   - State clearly: "I think X is the root cause because Y"
   - Write it down
   - Be specific, not vague

2. **Test Minimally**
   - Make the SMALLEST possible change to test hypothesis
   - One variable at a time
   - Don't fix multiple things at once

3. **Verify Before Continuing**
   - Did it work? Yes → Phase 4
   - Didn't work? Form NEW hypothesis
   - DON'T add more fixes on top

4. **When You Don't Know**
   - Say "I don't understand X"
   - Don't pretend to know
   - Ask for help
   - Research more

### Phase 4: Implementation

**Fix the root cause, not the symptom:**

1. **Create Failing Test Case**
   - Simplest possible reproduction
   - Automated test if possible
   - One-off test script if no framework
   - MUST have before fixing
   - Use the `superpowers:test-driven-development` skill for writing proper failing tests

2. **Implement Single Fix**
   - Address the root cause identified
   - ONE change at a time
   - No "while I'm here" improvements
   - No bundled refactoring

3. **Verify Fix**
   - Test passes now?
   - No other tests broken?
   - Issue actually resolved?

4. **If Fix Doesn't Work**
   - STOP
   - Count: How many fixes have you tried?
   - If < 3: Return to Phase 1, re-analyze with new information
   - **If ≥ 3: STOP and question the architecture (step 5 below)**
   - DON'T attempt Fix #4 without architectural discussion

5. **If 3+ Fixes Failed: Question Architecture**

   **Pattern indicating architectural problem:**
   - Each fix reveals new shared state/coupling/problem in different place
   - Fixes require "massive refactoring" to implement
   - Each fix creates new symptoms elsewhere

   **STOP and question fundamentals:**
   - Is this pattern fundamentally sound?
   - Are we "sticking with it through sheer inertia"?
   - Should we refactor architecture vs. continue fixing symptoms?

   **Discuss with your human partner before attempting more fixes**

   This is NOT a failed hypothesis - this is a wrong architecture.

## Red Flags - STOP and Follow Process

If you catch yourself thinking:
- "Quick fix for now, investigate later"
- "Just try changing X and see if it works"
- "Add multiple changes, run tests"
- "Skip the test, I'll manually verify"
- "It's probably X, let me fix that"
- "I don't fully understand but this might work"
- "Pattern says X but I'll adapt it differently"
- "Here are the main problems: [lists fixes without investigation]"
- Proposing solutions before tracing data flow
- **"One more fix attempt" (when already tried 2+)**
- **Each fix reveals new problem in different place**

**ALL of these mean: STOP. Return to Phase 1.**

**If 3+ fixes failed:** Question the architecture (see Phase 4.5)

## your human partner's Signals You're Doing It Wrong

**Watch for these redirections:**
- "Is that not happening?" - You assumed without verifying
- "Will it show us...?" - You should have added evidence gathering
- "Stop guessing" - You're proposing fixes without understanding
- "Ultrathink this" - Question fundamentals, not just symptoms
- "We're stuck?" (frustrated) - Your approach isn't working

**When you see these:** STOP. Return to Phase 1.

## Common Rationalizations

| Excuse | Reality |
|--------|---------|
| "Issue is simple, don't need process" | Simple issues have root causes too. Process is fast for simple bugs. |
| "Emergency, no time for process" | Systematic debugging is FASTER than guess-and-check thrashing. |
| "Just try this first, then investigate" | First fix sets the pattern. Do it right from the start. |
| "I'll write test after confirming fix works" | Untested fixes don't stick. Test first proves it. |
| "Multiple fixes at once saves time" | Can't isolate what worked. Causes new bugs. |
| "Reference too long, I'll adapt the pattern" | Partial understanding guarantees bugs. Read it completely. |
| "I see the problem, let me fix it" | Seeing symptoms ≠ understanding root cause. |
| "One more fix attempt" (after 2+ failures) | 3+ failures = architectural problem. Question pattern, don't fix again. |

## Quick Reference

| Phase | Key Activities | Success Criteria |
|-------|---------------|------------------|
| **1. Root Cause** | Read errors, reproduce, check changes, gather evidence | Understand WHAT and WHY |
| **2. Pattern** | Find working examples, compare | Identify differences |
| **3. Hypothesis** | Form theory, test minimally | Confirmed or new hypothesis |
| **4. Implementation** | Create test, fix, verify | Bug resolved, tests pass |

## When Process Reveals "No Root Cause"

If systematic investigation reveals issue is truly environmental, timing-dependent, or external:

1. You've completed the process
2. Document what you investigated
3. Implement appropriate handling (retry, timeout, error message)
4. Add monitoring/logging for future investigation

**But:** 95% of "no root cause" cases are incomplete investigation.

## Supporting Techniques

These techniques are part of systematic debugging and available in this directory:

- **`root-cause-tracing.md`** - Trace bugs backward through call stack to find original trigger
- **`defense-in-depth.md`** - Add validation at multiple layers after finding root cause
- **`condition-based-waiting.md`** - Replace arbitrary timeouts with condition polling

**Related skills:**
- **superpowers:test-driven-development** - For creating failing test case (Phase 4, Step 1)
- **superpowers:verification-before-completion** - Verify fix worked before claiming success

## Real-World Impact

From debugging sessions:
- Systematic approach: 15-30 minutes to fix
- Random fixes approach: 2-3 hours of thrashing
- First-time fix rate: 95% vs 40%
- New bugs introduced: Near zero vs common

---

そうして。

---

Base directory for this skill: /Users/ta93abe/.claude/plugins/cache/claude-plugins-official/superpowers/4.3.0/skills/writing-plans

# Writing Plans

## Overview

Write comprehensive implementation plans assuming the engineer has zero context for our codebase and questionable taste. Document everything they need to know: which files to touch for each task, code, testing, docs they might need to check, how to test it. Give them the whole plan as bite-sized tasks. DRY. YAGNI. TDD. Frequent commits.

Assume they are a skilled developer, but know almost nothing about our toolset or problem domain. Assume they don't know good test design very well.

**Announce at start:** "I'm using the writing-plans skill to create the implementation plan."

**Context:** This should be run in a dedicated worktree (created by brainstorming skill).

**Save plans to:** `docs/plans/YYYY-MM-DD-<feature-name>.md`

## Bite-Sized Task Granularity

**Each step is one action (2-5 minutes):**
- "Write the failing test" - step
- "Run it to make sure it fails" - step
- "Implement the minimal code to make the test pass" - step
- "Run the tests and make sure they pass" - step
- "Commit" - step

## Plan Document Header

**Every plan MUST start with this header:**

```markdown
# [Feature Name] Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** [One sentence describing what this builds]

**Architecture:** [2-3 sentences about approach]

**Tech Stack:** [Key technologies/libraries]

---
```

## Task Structure

````markdown
### Task N: [Component Name]

**Files:**
- Create: `exact/path/to/file.py`
- Modify: `exact/path/to/existing.py:123-145`
- Test: `tests/exact/path/to/test.py`

**Step 1: Write the failing test**

```python
def test_specific_behavior():
    result = function(input)
    assert result == expected
```

**Step 2: Run test to verify it fails**

Run: `pytest tests/path/test.py::test_name -v`
Expected: FAIL with "function not defined"

**Step 3: Write minimal implementation**

```python
def function(input):
    return expected
```

**Step 4: Run test to verify it passes**

Run: `pytest tests/path/test.py::test_name -v`
Expected: PASS

**Step 5: Commit**

```bash
git add tests/path/test.py src/path/file.py
git commit -m "feat: add specific feature"
```
````

## Remember
- Exact file paths always
- Complete code in plan (not "add validation")
- Exact commands with expected output
- Reference relevant skills with @ syntax
- DRY, YAGNI, TDD, frequent commits

## Execution Handoff

After saving the plan, offer execution choice:

**"Plan complete and saved to `docs/plans/<filename>.md`. Two execution options:**

**1. Subagent-Driven (this session)** - I dispatch fresh subagent per task, review between tasks, fast iteration

**2. Parallel Session (separate)** - Open new session with executing-plans, batch execution with checkpoints

**Which approach?"**

**If Subagent-Driven chosen:**
- **REQUIRED SUB-SKILL:** Use superpowers:subagent-driven-development
- Stay in this session
- Fresh subagent per task + code review

**If Parallel Session chosen:**
- Guide them to open new session in worktree
- **REQUIRED SUB-SKILL:** New session uses superpowers:executing-plans

---

## Context

- Current git status: On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   action.yml

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	docs/

no changes added to commit (use "git add" and/or "git commit -a")
- Current git diff (staged and unstaged changes): diff --git a/action.yml b/action.yml
index 7e4734c..cd82f55 100644
--- a/action.yml
+++ b/action.yml
@@ -91,12 +91,57 @@ runs:
         echo "CI schema: ${schema}"
 
     # ---- Step 2: Setup dbt ----
-    - name: Setup dbt
-      uses: ./actions/setup
-      with:
-        adapter: ${{ inputs.adapter }}
-        dbt-version: ${{ inputs.dbt-version == 'latest' && '' || inputs.dbt-version }}
-        project-dir: ${{ inputs.project-dir }}
+    - name: Validate and normalize adapter
+      id: normalize-adapter
+      shell: bash
+      env:
+        INPUT_ADAPTER: ${{ inputs.adapter }}
+      run: |
+        adapter="$INPUT_ADAPTER"
+        adapter="${adapter#dbt-}"
+        adapter="${adapter,,}"
+
+        case "$adapter" in
+          snowflake)
+            echo "adapter_package=dbt-snowflake" >> "$GITHUB_OUTPUT"
+            ;;
+          *)
+            echo "::error::Unsupported adapter: ${INPUT_ADAPTER}. Supported adapters: snowflake"
+            exit 1
+            ;;
+        esac
+
+    - name: Install uv
+      uses: astral-sh/setup-uv@v7
+
+    - name: Resolve dbt version
+      id: resolve-dbt-version
+      shell: bash
+      env:
+        ACTION_PATH: ${{ github.action_path }}
+        DBT_VERSION_INPUT: ${{ inputs.dbt-version == 'latest' && '' || inputs.dbt-version }}
+        DBT_PROJECT_DIR: ${{ inputs.project-dir }}
+      run: |
+        version=$("${ACTION_PATH}/scripts/resolve-version.sh" \
+          "$DBT_VERSION_INPUT" \
+          "$DBT_PROJECT_DIR")
+        echo "version=$version" >> "$GITHUB_OUTPUT"
+
+    - name: Install dbt
+      id: install-dbt
+      shell: bash
+      env:
+        DBT_VERSION: ${{ steps.resolve-dbt-version.outputs.version }}
+        DBT_ADAPTER_PACKAGE: ${{ steps.normalize-adapter.outputs.adapter_package }}
+      run: |
+        if [[ -n "$DBT_VERSION" ]]; then
+          uv pip install --system "dbt-core==${DBT_VERSION}" "${DBT_ADAPTER_PACKAGE}"
+        else
+          uv pip install --system dbt-core "${DBT_ADAPTER_PACKAGE}"
+        fi
+
+        installed_version=$(dbt --version | grep -oP 'installed: \K[0-9]+\.[0-9]+\.[0-9]+' | head -1 || dbt --version | grep -oE '[0-9]+\.[0-9]+\.[0-9]+' | head -1)
+        echo "dbt-version=${installed_version}" >> "$GITHUB_OUTPUT"
 
     # ---- Step 3: dbt deps ----
     - name: dbt deps
- Current branch: main
- Recent commits: 512054f fix: validate semver format in release tag lookup (#5)
487d6de ci: auto-release on merge with PR label versioning (#4)
b96bf58 ci: establish release cycle with CI and tag-based releases (#3)
d232ffe refactor: centralize adapter normalization in setup action
388fd76 fix: eliminate expression injection and command injection vulnerabilities
2ad1faa chore: add Marketplace branding and rewrite README
81c35dd chore: change license from Apache 2.0 to MIT
214ddc4 feat: support multiple file formats for dbt version resolution
539cb1e chore: remove generate-docs feature (#1)
52b2e0f feat: auto-set PR-specific schema in CI mode

## Your task

Based on the above changes, create a single git commit.

You have the capability to call multiple tools in a single response. Stage and create the commit using a single message. Do not use any other tools or do anything else. Do not send any other text or messages besides these tool calls.

---

Base directory for this skill: /Users/ta93abe/.claude/skills/pr

# pr

Pull Requestの作成・レビュー対応を行うスキル。

## サブコマンド

### /pr create (デフォルト)

PRを作成する。

**動作:**
1. `git status` で現在のブランチと変更を確認
2. `git log main..HEAD` でコミット履歴を確認
3. `git diff main...HEAD` で全体の変更を確認
4. 変更内容を分析してPRの説明文を生成
5. `gh pr create` でPRを作成
6. 変更の種類を確認し、リリースラベル（`patch`/`minor`/`major`）を付与

**リリースラベル判断基準:**
- `patch`: バグ修正、ドキュメント更新、リファクタリング、CI修正
- `minor`: 新機能追加、既存機能の拡張
- `major`: 破壊的変更（後方互換性のない変更）

デフォルトは `patch`。判断に迷った場合はユーザーに確認する。

**PR形式:**
```markdown
## Summary
<変更の概要を箇条書き>

## Test plan
<テスト方法のチェックリスト>

Generated with [Claude Code](https://claude.com/claude-code)
```

### /pr review

PRのレビューコメントに対応し、問題なければマージまで行う。

**動作:**
1. `gh pr view` でPR情報を取得
2. `gh api` でレビューコメントを取得
3. 各コメントの指摘内容を分析
4. 必要な修正を実施
5. 修正をコミット・プッシュ
6. CIの状態を確認
7. 重大な問題がなければ `gh pr merge` でマージ

**マージ判断基準:**
- 重大な問題（セキュリティ、破壊的変更）がない
- CIが通っている
- 軽微な指摘は対応済み、または次回対応として許容できる

**マージ方法:**
- デフォルトは squash merge (`--squash`)
- マージ後にブランチを削除 (`--delete-branch`)

### /pr status

現在のPRの状態を確認する。

**動作:**
1. `gh pr status` でPR一覧を表示
2. CIの状態を確認
3. レビューの状態を確認

## 注意事項

- PRを作成する前にリモートにプッシュされていることを確認
- ベースブランチ（通常はmain）との差分を確認
- CIが通っていることを確認してからマージ依頼

---

entire/checkpoints/v1 このブランチはPull Requestしないから表示しないでほしい。

---

[Request interrupted by user for tool use]

---

Base directory for this skill: /Users/ta93abe/.claude/skills/pr

# pr

Pull Requestの作成・レビュー対応を行うスキル。

## サブコマンド

### /pr create (デフォルト)

PRを作成する。

**動作:**
1. `git status` で現在のブランチと変更を確認
2. `git log main..HEAD` でコミット履歴を確認
3. `git diff main...HEAD` で全体の変更を確認
4. 変更内容を分析してPRの説明文を生成
5. `gh pr create` でPRを作成
6. 変更の種類を確認し、リリースラベル（`patch`/`minor`/`major`）を付与

**リリースラベル判断基準:**
- `patch`: バグ修正、ドキュメント更新、リファクタリング、CI修正
- `minor`: 新機能追加、既存機能の拡張
- `major`: 破壊的変更（後方互換性のない変更）

デフォルトは `patch`。判断に迷った場合はユーザーに確認する。

**PR形式:**
```markdown
## Summary
<変更の概要を箇条書き>

## Test plan
<テスト方法のチェックリスト>

Generated with [Claude Code](https://claude.com/claude-code)
```

### /pr review

PRのレビューコメントに対応し、問題なければマージまで行う。

**動作:**
1. `gh pr view` でPR情報を取得
2. `gh api` でレビューコメントを取得
3. 各コメントの指摘内容を分析
4. 必要な修正を実施
5. 修正をコミット・プッシュ
6. CIの状態を確認
7. 重大な問題がなければ `gh pr merge` でマージ

**マージ判断基準:**
- 重大な問題（セキュリティ、破壊的変更）がない
- CIが通っている
- 軽微な指摘は対応済み、または次回対応として許容できる

**マージ方法:**
- デフォルトは squash merge (`--squash`)
- マージ後にブランチを削除 (`--delete-branch`)

### /pr status

現在のPRの状態を確認する。

**動作:**
1. `gh pr status` でPR一覧を表示
2. CIの状態を確認
3. レビューの状態を確認

## 注意事項

- PRを作成する前にリモートにプッシュされていることを確認
- ベースブランチ（通常はmain）との差分を確認
- CIが通っていることを確認してからマージ依頼


ARGUMENTS: review

---

CI失敗の原因は dbt-jobs@v0.1.2 のアクション内部の問題です。uv pip install --system がUbuntuの externally managed
  Python 環境で失敗しています。

  error: The interpreter at /usr is externally managed
  hint: Virtual environments were not considered due to the `--system` flag


  これは dbt-jobs アクション側で --system フラグではなく venv を使うように修正する必要があります。v0.1.2
  のアクションコードに uv pip install --system が含まれているのが原因です。

  dbt-jobs リポジトリ側でこの問題を修正して v0.1.3 をリリースするか、--system の代わりに --break-system-packages
  を使うか、venv を作成する必要があります。

---

Base directory for this skill: /Users/ta93abe/.claude/skills/pr

# pr

Pull Requestの作成・レビュー対応を行うスキル。

## サブコマンド

### /pr create (デフォルト)

PRを作成する。

**動作:**
1. `git status` で現在のブランチと変更を確認
2. `git log main..HEAD` でコミット履歴を確認
3. `git diff main...HEAD` で全体の変更を確認
4. 変更内容を分析してPRの説明文を生成
5. `gh pr create` でPRを作成
6. 変更の種類を確認し、リリースラベル（`patch`/`minor`/`major`）を付与

**リリースラベル判断基準:**
- `patch`: バグ修正、ドキュメント更新、リファクタリング、CI修正
- `minor`: 新機能追加、既存機能の拡張
- `major`: 破壊的変更（後方互換性のない変更）

デフォルトは `patch`。判断に迷った場合はユーザーに確認する。

**PR形式:**
```markdown
## Summary
<変更の概要を箇条書き>

## Test plan
<テスト方法のチェックリスト>

Generated with [Claude Code](https://claude.com/claude-code)
```

### /pr review

PRのレビューコメントに対応し、問題なければマージまで行う。

**動作:**
1. `gh pr view` でPR情報を取得
2. `gh api` でレビューコメントを取得
3. 各コメントの指摘内容を分析
4. 必要な修正を実施
5. 修正をコミット・プッシュ
6. CIの状態を確認
7. 重大な問題がなければ `gh pr merge` でマージ

**マージ判断基準:**
- 重大な問題（セキュリティ、破壊的変更）がない
- CIが通っている
- 軽微な指摘は対応済み、または次回対応として許容できる

**マージ方法:**
- デフォルトは squash merge (`--squash`)
- マージ後にブランチを削除 (`--delete-branch`)

### /pr status

現在のPRの状態を確認する。

**動作:**
1. `gh pr status` でPR一覧を表示
2. CIの状態を確認
3. レビューの状態を確認

## 注意事項

- PRを作成する前にリモートにプッシュされていることを確認
- ベースブランチ（通常はmain）との差分を確認
- CIが通っていることを確認してからマージ依頼